{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbbdf46e-2715-4bec-866c-e9d00b08d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e17df970-db83-45ac-acca-05d13c1e2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e0530b7-9225-4e9c-97c1-4da5c84c7870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "64fe2e44-a55a-4364-be0e-229f1f33633f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8edfdd0-277b-41f6-a9cb-266a1bf8ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4f5af5c-250f-4435-b5db-3a2aec4457e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6955dce-f8f9-47e6-af30-3ca8f6dd950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text=str(text).lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text) \n",
    "    tokens = word_tokenize(str(text).lower(), language='english') \n",
    "    tokens = [word for word in tokens if word not in stop_words ]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d36248ab-b36c-41bb-bf50-e63a2ca850b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.7 s, sys: 137 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['review']=df['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca632368-3375-43af-8589-886b1cf5cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77bfe982-3278-462c-8f0d-3b102196377a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47808</th>\n",
       "      <td>[caught, little, gem, totally, accident, back,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>[believe, let, movie, accomplish, favor, frien...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43069</th>\n",
       "      <td>[spoiler, alert, gets, nerve, people, remake, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19413</th>\n",
       "      <td>[one, thing, learnt, watching, george, romero,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13673</th>\n",
       "      <td>[remember, theaters, reviews, said, horrible, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31092</th>\n",
       "      <td>[man, named, walt, disney, mission, satisfy, f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22917</th>\n",
       "      <td>[first, time, saw, shades, sneakpreview, even,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47481</th>\n",
       "      <td>[waste, time, danger, watch, tempted, tear, dv...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35597</th>\n",
       "      <td>[far, pathetic, movie, indian, cinema, cinema,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27491</th>\n",
       "      <td>[movie, forever, left, impression, watched, fr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "47808  [caught, little, gem, totally, accident, back,...  positive\n",
       "20154  [believe, let, movie, accomplish, favor, frien...  negative\n",
       "43069  [spoiler, alert, gets, nerve, people, remake, ...  negative\n",
       "19413  [one, thing, learnt, watching, george, romero,...  negative\n",
       "13673  [remember, theaters, reviews, said, horrible, ...  negative\n",
       "...                                                  ...       ...\n",
       "31092  [man, named, walt, disney, mission, satisfy, f...  positive\n",
       "22917  [first, time, saw, shades, sneakpreview, even,...  negative\n",
       "47481  [waste, time, danger, watch, tempted, tear, dv...  negative\n",
       "35597  [far, pathetic, movie, indian, cinema, cinema,...  negative\n",
       "27491  [movie, forever, left, impression, watched, fr...  negative\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0a244d1-33bf-442e-82b5-73e57397cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b0a0287-1af8-4d87-8b1d-392812fdc8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Word2Vec(sentences=df_train['review'],vector_size=150, window=5, min_count=5, sg=1,negative=10,              \n",
    "    epochs=10,\n",
    "    workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a249054d-4890-4103-9f9f-2b205784cb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d163cd4-e33b-4b06-948e-89ef0331f3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=35582, vector_size=150, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "920aae54-ccc9-4bc4-a88f-79bd2fcda87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08061524 -0.10841177  0.04403988 -0.0519916   0.14087656  0.06184833\n",
      " -0.24752639  0.26383737 -0.11852185  0.34366798 -0.05538724 -0.09480063\n",
      "  0.01151957  0.21424372  0.00629685 -0.12441132 -0.20403633 -0.05215696\n",
      "  0.22864334  0.09753177 -0.10274705 -0.2399808  -0.01001993  0.18332914\n",
      " -0.02238299  0.0977257  -0.13734534 -0.1922795   0.45375434 -0.16030376\n",
      "  0.00164344 -0.17975797 -0.31491736 -0.24374908 -0.39661503 -0.3776931\n",
      "  0.4699513   0.16188343  0.26698908 -0.25087214 -0.20298553 -0.1170556\n",
      " -0.30032513 -0.2508713  -0.14116827  0.08885399 -0.15304635  0.22894646\n",
      "  0.06510173  0.18533343  0.01730995  0.21190093 -0.47146156  0.04427177\n",
      " -0.24490424  0.00508768 -0.1573345   0.29002944 -0.20856445 -0.4389199\n",
      "  0.00357996  0.12701607 -0.00384624  0.04798952  0.00963961 -0.22681303\n",
      "  0.08799466  0.02418166 -0.10387127  0.17224848  0.10285519  0.26784584\n",
      "  0.20115513 -0.5575286   0.20655006 -0.05913524 -0.3402288   0.1262\n",
      " -0.05128352  0.06775261  0.09565359 -0.08181308  0.1312529   0.4539853\n",
      " -0.36861816  0.03323941  0.02302289  0.17153485  0.01710639  0.05893561\n",
      "  0.19514719  0.00675381  0.12337477 -0.11711147 -0.12791385 -0.14379938\n",
      "  0.01847989  0.24653454 -0.22034514  0.08990271  0.08137356 -0.08173497\n",
      " -0.13861662 -0.02299503 -0.07918298 -0.23401666  0.04971893  0.51103187\n",
      " -0.3021808  -0.36340517 -0.17938244 -0.3410003   0.411883    0.12348513\n",
      "  0.15282759  0.30124193 -0.05701583  0.3408738  -0.13589445 -0.11090644\n",
      " -0.00075517  0.45560354 -0.16023651  0.17610978  0.2611015   0.08731905\n",
      " -0.05455231 -0.01531032 -0.33066255  0.2636386   0.12900157  0.14106771\n",
      " -0.15019116 -0.23388256  0.25153768  0.3993022  -0.02562756  0.13575536\n",
      " -0.40097705  0.23450005 -0.0242844  -0.29586083 -0.14821716 -0.08734555\n",
      "  0.29552025  0.3959623  -0.3104403   0.19073622  0.37029418 -0.21930912]\n"
     ]
    }
   ],
   "source": [
    "vector = model.wv['bad']   \n",
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1586dc16-b37f-45b2-a4c4-4149ac0b4d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fraidy', 0.6252961754798889), ('mouse', 0.6228405237197876), ('meow', 0.603987991809845), ('ev', 0.6021479368209839), ('kittens', 0.5708582997322083), ('dog', 0.5674090385437012), ('pyewacket', 0.5596545934677124), ('skunk', 0.5587746500968933), ('malley', 0.5562594532966614), ('himalayan', 0.5372576117515564)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.wv.most_similar('cat', topn=10)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9dd7135-4b18-4319-af08-cf9bb8b094f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "vector_size = 150\n",
    "X = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a44f61c6-645f-4864-a94f-360b53242ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_vectors(tokens, model, max_len, vector_size):\n",
    "    seq = []\n",
    "    for word in tokens[:max_len]:\n",
    "        if word in model.wv:\n",
    "            seq.append(model.wv[word])\n",
    "        else:\n",
    "            seq.append(np.zeros(vector_size))\n",
    "    while len(seq) < max_len:\n",
    "        seq.append(np.zeros(vector_size))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed68ee6a-3d67-4d3d-9ea2-3045c5ae10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([tokens_to_vectors(tokens, model, max_len, vector_size) for tokens in df_train['review']])\n",
    "X_test  = np.array([tokens_to_vectors(tokens, model, max_len, vector_size) for tokens in df_test['review']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80b55ff3-3d68-4aab-8f7d-34fe8daf6aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47808    1\n",
       "20154    0\n",
       "43069    0\n",
       "19413    0\n",
       "13673    0\n",
       "        ..\n",
       "31092    1\n",
       "22917    0\n",
       "47481    0\n",
       "35597    0\n",
       "27491    0\n",
       "Name: sentiment, Length: 40000, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d5d72663-bbed-44ff-9337-44525dce263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=df_train['sentiment'].apply(lambda x: 1 if x=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63354514-b7af-407a-b570-90c530e3ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=df_test['sentiment'].apply(lambda x: 1 if x=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5cd947db-9385-434b-8c4c-fb615233219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47808    1\n",
       "20154    0\n",
       "43069    0\n",
       "19413    0\n",
       "13673    0\n",
       "        ..\n",
       "31092    1\n",
       "22917    0\n",
       "47481    0\n",
       "35597    0\n",
       "27491    0\n",
       "Name: sentiment, Length: 40000, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa7035a8-b114-4a2a-af21-76b6e9790971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f5f20a8-bb52-4b6f-a6ff-a7b101380e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0ccde88-7cfc-4dbe-a208-8755f5fc86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train_tensor=torch.tensor(y_train.values,dtype=torch.long)\n",
    "y_test_tensor=torch.tensor(y_test.values,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "81e0eae8-df6f-4d67-8f9b-24c25b806df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6e6fe810-e538-4061-970a-2f01df85d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.5):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.lstm=nn.LSTM(input_size,hidden_size,num_layers,batch_first=True,dropout=dropout)\n",
    "        self.fc=nn.Linear(hidden_size,num_classes)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        out = h_n[-1]\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "  # сюда пойдут \"чистые\" логиты\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3167e521-051d-4e1f-9c7e-beeb9e03b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vector_size     \n",
    "hidden_size = 128         \n",
    "num_layers = 2               \n",
    "num_classes = 2              \n",
    "learning_rate = 0.001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9c420802-0c97-4fdd-8c09-fa831e253a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SentimentLSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f3ffd5ac-592b-4f55-a76a-d39f1f8a1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1154430b-84fb-4d69-9a05-24e51812db86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6890\n",
      "Epoch [2/10], Loss: 0.6906\n",
      "Epoch [3/10], Loss: 0.6783\n",
      "Epoch [4/10], Loss: 0.4090\n",
      "Epoch [5/10], Loss: 0.3296\n",
      "Epoch [6/10], Loss: 0.3182\n",
      "Epoch [7/10], Loss: 0.3078\n",
      "Epoch [8/10], Loss: 0.3004\n",
      "Epoch [9/10], Loss: 0.2903\n",
      "Epoch [10/10], Loss: 0.2848\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model2.train()\n",
    "    total_loss = 0\n",
    "    for X_batch,y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model2(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b37573b1-9f78-4ac2-9d3a-363899ce456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.18%\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model2(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9cd029-11f9-41ea-a8c9-62526d9322a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworst news \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m text\u001b[38;5;241m=\u001b[39m\u001b[43mclean_text\u001b[49m(text)\n\u001b[1;32m      3\u001b[0m X_input \u001b[38;5;241m=\u001b[39m tokens_to_vectors(text,model, max_len, vector_size)  \u001b[38;5;66;03m# model — это твой Word2Vec\u001b[39;00m\n\u001b[1;32m      4\u001b[0m X_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_input, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_text' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"worst news \"\n",
    "text=clean_text(text)\n",
    "X_input = tokens_to_vectors(text,model, max_len, vector_size)  # model — это твой Word2Vec\n",
    "X_input = torch.tensor(X_input, dtype=torch.float32)\n",
    "X_input = X_input.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model2(X_input)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    print(\"Предсказанный класс:\", predicted.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4514e5-7d9d-4947-8a77-0e9f5401c656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2387849-90a7-4470-93c7-9dba0dcda1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
